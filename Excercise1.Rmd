---
title: "LDpred2 Excercise"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

This excercise generally follows the vignette by Florian Privé available online [**here**](https://privefl.github.io/bigsnpr/articles/LDpred2.html).

The most relevant literature is [**Privé *et al.*, bioRxiv 2020**](https://doi.org/10.1101/2020.04.28.066720), which presents LDpred2. For more details on the LDpred method please see [**Vilhjálmsson *et al.*, AJHG 2015**](https://doi.org/10.1016/j.ajhg.2015.09.001). Furthermore the R packages `bigsnpr` and `bigstatr` are presented and extended in following publications [Privé *et al.*, Bioinformatics 2018](https://doi.org/10.1093/bioinformatics/bty185), [Privé *et al.*, Genetics 2019](https://www.genetics.org/content/212/1/65), [Privé *et al.*, AJHG 2019](https://doi.org/10.1016/j.ajhg.2019.11.001), [Privé *et al.*, Bioinformatics 2020](https://doi.org/10.1093/bioinformatics/btaa520).

## Prerequisites 
There are several requirements for completing this excercise.  

1. R studio with R version \>3.3.
2. R packages bigsnpr (and bigstatr). For most users executing the 
` install.packages("bigsnpr") ` ensures this.
3. The test dataset should be downloaded and unzipped.


## 1. Load and inspect genotype data 
First we load the bigsnpr package.
```{r}
library(bigsnpr)
library(R.utils)

#For plotting
library(ggplot2) 
library(viridis)
```


Then we read from bed/bim/fam, it generates .bk and .rds files.  Make sure the data folder is in the working directory.  You can check the working directory using `getwd()` and change it using `setwd("your/working/directory")`.
```{r}
setwd("/Users/au507860/Dropbox/Cloud_folder/Courses/DiabetesAcademy2020")
snp_readBed("tmp-data/public-data.bed")
```

Load the data and store in the "bigSNP" R session object
```{r}
obj.bigSNP <- snp_attach("tmp-data/public-data.rds")
```

Inspect the contents of the file
```{r}
str(obj.bigSNP, max.level = 2, strict.width = "cut")
```

Get aliases for useful bigSNP variables
```{r}
G   <- obj.bigSNP$genotypes
CHR <- obj.bigSNP$map$chromosome
POS <- obj.bigSNP$map$physical.pos
y   <- obj.bigSNP$fam$affection - 1
NCORES <- nb_cores()
```

### 1.1 Preparing an LD reference: Principal Component Analysis (PCA) and Relateness
LDpred requires a LD reference, which are set of genotypes that ideally suffices two following conditions.

1. The ancestry of the LD reference should be similar as the sample for which the summary statistics are based on.

2. The individuals should not have close genetic relateness, e.g. more distant than cousins.

The test/validation data can sometimes be used as LD reference. You can use `bigsnpr` to do prune the data to ensure it suffices the two conditions above.  

The details are shown in [**Privé *et al.*, Bioinformatics 2020**](https://doi.org/10.1093/bioinformatics/btaa520), and a vignette for how to conduct PCA analyses using the package can be found [**here**](https://privefl.github.io/bigsnpr/articles/bedpca.html).

First we download the 1000 genomes data, which can take time if the internet connection is slow.
```{r}
bedfile <- download_1000G("data")
```

#### Relateness
First, let us detect all pairs of related individuals.

```{r}
plink2 <- download_plink2("data")
rel <- snp_plinkKINGQC(
  plink2.path = plink2,
  bedfile.in = bedfile,
  thr.king = 2^-4.5,
  make.bed = FALSE,
  ncores = nb_cores()
)
str(rel)
```


#### Principal Component Analysis (PCA)
We then prune related individuals and compute PCA on the remaining (unrelated) individuals. The function `bed_autoSVD()` iteratively prunes variants to reduce the risk of the PCA capturing Linkage Disequilibrium (LD).

```{r}
(obj.bed <- bed(bedfile))
ind.rel <- match(c(rel$IID1, rel$IID2), obj.bed$fam$sample.ID)
ind.norel <- rows_along(obj.bed)[-ind.rel]

obj.svd <- bed_autoSVD(obj.bed, ind.row = ind.norel, k = 20,
                       ncores = nb_cores())
```

We can plot these PCs.
```{r}
anc_info <- read.delim('data/1000G_phase3_common_norel.fam2')[-ind.rel,]

plot_grid(plotlist = lapply(1:4, function(k) {
  plot(obj.svd, type = "scores", scores = 2 * k - 1:0, coeff = 0.6) +
  aes(color=anc_info$Super.Population) +
  scale_color_viridis(name="Ancestry", discrete = TRUE)
}), scale = 0.95)
```



#### Outlier sample detection (quality control)
Then, we look at if there are individual outliers, that could be evidence for genotyping issues.

```{r}
prob <- bigutilsr::prob_dist(obj.svd$u, ncores = nb_cores())
S <- prob$dist.self / sqrt(prob$dist.nn)

```
  
We can then rerun the PCA without these outliers
```{r}
ind.row <- ind.norel[S < 0.5]
ind.col <- attr(obj.svd, "subset")
obj.svd2 <- bed_autoSVD(obj.bed, ind.row = ind.row,
                        ind.col = ind.col, thr.r2 = NA,
                        k = 20, ncores = nb_cores())
```

#### Final PCA with all individuals
We would still like to obtain the PCA values for the remaining individuals.  We do this by projecting them onto these PCs, to get PCs for all inviduals.

```{r}
PCs <- matrix(NA, nrow(obj.bed), ncol(obj.svd2$u))
PCs[ind.row, ] <- predict(obj.svd2)

proj <- bed_projectSelfPCA(obj.svd2, obj.bed,
                           ind.row = rows_along(obj.bed)[-ind.row],
                           ncores = 1) # useless -> too few individuals
PCs[-ind.row, ] <- proj$OADP_proj
```

We can plot the PCs again.
```{r}
anc_info <- read.delim('data/1000G_phase3_common_norel.fam2')
PCs_df <- as.data.frame(PCs)
colnames(PCs_df) <- paste("PC",1:20,sep="")

ggplot(data = PCs_df, mapping = aes(x = PC1, y = PC2)) +
    scale_color_viridis(name="Ancestry", discrete = TRUE)+
    geom_point(aes(color = anc_info$Super.Population))

ggplot(data = PCs_df, mapping = aes(x = PC3, y = PC4)) +
    scale_color_viridis(name="Ancestry", discrete = TRUE)+
    geom_point(aes(color = anc_info$Super.Population))

```


#### Restricting to a specific ancestry

We want the set of individuals in our LD reference to have similar ancestry as the ones in our summary statistics. E.g. if we want to use summary statistics based on individuals with East Asian ancestry, we should exclude individuals that have a different ancestry in our LD reference. If labels are available we can use these. If not, then we can project the LD reference data on to 1KG and exclude individuals that land far away from individuals with the target ancestry. You can use functions `cov <- bigutilsr::covrob_ogk(PC[ind_eur, ])` and `log_dist <- log(mahalanobis(PC, center = cov$center, cov = cov$cov))` for this purpose.


### 1.2 Load external summary statistics 

To train the polygenic risk score, the user should load external summary statistics
```{r}
sumstats <- bigreadr::fread2("tmp-data/public-data-sumstats.txt")
str(sumstats)
```

We split genotype data using part of the data to learn parameters of stacking and another part of the data to evaluate statistical properties of polygenic risk score such as AUC. Here we consider that there are 400 individuals in the training set.
```{r}
set.seed(1)
ind.val <- sample(nrow(G), 400)
ind.test <- setdiff(rows_along(G), ind.val)
```

### 1.3 Matching and synchronising variants across genotype data and summary statistics

To match variants contained in genotype data and summary statistics, the variables "chr" (chromosome number), "pos" (genetic position), "a0" (reference allele) and "a1" (derived allele) should be available in the summary statistics and in the genotype data. These 4 variables are used to match variants between the two data frames.

```{r}
sumstats$n_eff <- 4 / (1 / sumstats$n_case + 1 / sumstats$n_control)
sumstats$n_case <- sumstats$n_control <- NULL
names(sumstats) <- c("chr", "rsid", "pos", "a0", "a1", "beta", "beta_se", "p", "n_eff")
map <- obj.bigSNP$map[-(2:3)]
names(map) <- c("chr", "pos", "a0", "a1")
info_snp <- snp_match(sumstats, map)
```

If no or few variants are actually flipped, you might want to disable the strand flipping option. Here, these are simulated data so all variants use the same strand and the same reference.

```{r}
info_snp <- snp_match(sumstats, map, strand_flip = FALSE)
```

### 1.4 Quality control of variants
Some variants may still not match in terms of allele frequencies and LD, and we want to exclude those. As this data is simulated, we do not have this issue, but in practice we reccommend you follow the proceedure outlined below (and in the supplementary note of the paper).
```{r}
sd <- sqrt(big_colstats(G,  ind.val, ncores = NCORES)$var)
sd_val <- sd[info_snp$`_NUM_ID_`]
sd_ss <- with(info_snp, 1 / sqrt(n_eff / 4 * beta_se^2))

is_bad <-
  sd_ss < (0.5 * sd_val) | sd_ss > (sd_val + 0.1) | sd_ss < 0.1 | sd_val < 0.05
qplot(sd_val, sd_ss, color = is_bad, alpha = I(0.5)) +
  theme_bigstatsr() +
  coord_equal() +
  scale_color_viridis_d(direction = -1) +
  geom_abline(linetype = 2, color = "red") +
  labs(x = "Standard deviations in the validation set",
       y = "Standard deviations derived from the summary statistics",
       color = "Removed?")
```

#### Restrict to HapMap3 variants
In practice, we recommend using the HapMap3 variants used in PRS-CS and the LDpred2 papers (until we find a better set of variants). Information about these variants can be retrieved with
```{r}
HM3_info <- readRDS(url("https://github.com/privefl/bigsnpr/raw/master/data-raw/hm3_variants.rds"))
str(HM3_info)
```

## 2 Computing LDpred2 scores for one chromosome
### 2.1 Calculating the linkage-disequilibirum (LD) matrix
First, you need to compute correlations between variants. We recommend to use a window size of 3 cM (see ref).

```{r}
POS2 <- snp_asGeneticPos(CHR, POS, dir = "tmp-data", ncores = 3)
## indices in info_snp
ind.chr <- which(info_snp$chr == 2)
df_beta <- info_snp[ind.chr, c("beta", "beta_se", "n_eff")]
## indices in G
ind.chr2 <- info_snp$`_NUM_ID_`[ind.chr]
corr0 <- snp_cor(G, ind.col = ind.chr2, ncores = NCORES,
                 infos.pos = POS2[ind.chr2], size = 3 / 1000)
corr <- bigsparser::as_SFBM(as(corr0, "dgCMatrix"))
```
### 2.2 Infinitesimal model
```{r}
(ldsc <- snp_ldsc2(corr0, df_beta))
h2_est <- ldsc[["h2"]]
beta_inf <- snp_ldpred2_inf(corr, df_beta, h2 = h2_est)
pred_inf <- big_prodVec(G, beta_inf, ind.row = ind.test, ind.col = ind.chr2)
AUCBoot(pred_inf, y[ind.test])
```
### 2.3 Grid of models
In practice, we recommend to test multiple values for h2 and p. 
```{r}
(h2_seq <- round(h2_est * c(0.7, 1, 1.4), 4))
(p_seq <- signif(seq_log(1e-4, 1, length.out = 17), 2))
(params <- expand.grid(p = p_seq, h2 = h2_seq, sparse = c(FALSE, TRUE)))
```
This takes several minutes if you do not have many cores
```{r}
beta_grid <- snp_ldpred2_grid(corr, df_beta, params, ncores = NCORES)
pred_grid <- big_prodMat(G, beta_grid, ind.col = ind.chr2)
params$score <- big_univLogReg(as_FBM(pred_grid[ind.val, ]), y[ind.val])$score
library(ggplot2)
ggplot(params, aes(x = p, y = score, color = as.factor(h2))) +
  theme_bigstatsr() +
  geom_point() +
  geom_line() +
  scale_x_log10(breaks = 10^(-5:0), minor_breaks = params$p) +
  facet_wrap(~ sparse, labeller = label_both) +
  labs(y = "GLM Z-Score", color = "h2") +
  theme(legend.position = "top", panel.spacing = unit(1, "lines"))
```


```{r}
library(dplyr)
params %>%
  mutate(sparsity = colMeans(beta_grid == 0), id = row_number()) %>%
  arrange(desc(score)) %>%
  mutate_at(c("score", "sparsity"), round, digits = 3) %>%
  slice(1:10)
```
You can then choose the best model according to your preferred criterion (e.g. max AUC). Here, we use the Z-Score from the regression of the phenotype by the PRS since we have found it more robust than using the AUC. It also enables adjusting for covariates in this step.

```{r}
best_grid_nosp <- params %>%
  mutate(id = row_number()) %>%
  filter(!sparse) %>%
  arrange(desc(score)) %>%
  slice(1) %>%
  pull(id) %>%
  beta_grid[, .]

pred_nosp <- big_prodVec(G, best_grid_nosp, ind.row = ind.test, ind.col = ind.chr2)
AUCBoot(pred_nosp, y[ind.test])
best_grid_sp <- params %>%
  mutate(id = row_number()) %>%
  filter(sparse) %>%
  arrange(desc(score)) %>%
  slice(1) %>%
  pull(id) %>%
  beta_grid[, .]

pred_sp <- big_prodVec(G, best_grid_sp, ind.row = ind.test, ind.col = ind.chr2)
AUCBoot(pred_sp, y[ind.test])
```

### 2.4 Automatic model
Actually, you can run many of them in parallel with different initial values for p.

```{r}
multi_auto <- snp_ldpred2_auto(corr, df_beta, h2_init = h2_est,
                               vec_p_init = seq_log(1e-4, 0.9, length.out = NCORES),
                               ncores = NCORES)
str(multi_auto)
```
You should verify if the chains “converged”. This is not the case here, which is probably because the data is so small.

```{r}
auto <- multi_auto[[1]]
plot_grid(
  qplot(y = auto$path_p_est) +
    theme_bigstatsr() +
    geom_hline(yintercept = auto$p_est, col = "blue") +
    scale_y_log10() +
    labs(y = "p"),
  qplot(y = auto$path_h2_est) +
    theme_bigstatsr() +
    geom_hline(yintercept = auto$h2_est, col = "blue") +
    labs(y = "h2"),
  ncol = 1, align = "hv"
)

beta_auto <- sapply(multi_auto, function(auto) auto$beta_est)
pred_auto <- big_prodMat(G, beta_auto, ind.row = ind.test, ind.col = ind.chr2)
```

Make sure the scale is okay (by comparing to LDpred2-inf and others auto) and possibly keep only the ones that looks good. (e.g. see code of paper), https://github.com/privefl/paper-ldpred2/blob/master/code/run-ldpred2.R#L101-L108.
```{r}
c(mad(pred_inf), apply(pred_auto, 2, mad))
# 
final_pred_auto <- rowMeans(pred_auto)
AUCBoot(final_pred_auto, y[ind.test])
```

## 3. Summary
We have seen how to run 3 versions of LDpred2 (“-inf”, “-grid” and “-auto”) for one chromosome. You need to do this for each chromosome and combine results. Normally, you can just sum the resulting scores, or equivalently, append the effect sizes.


